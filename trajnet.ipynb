{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trajnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfLvE74YdqwP",
        "outputId": "12c18f8c-b92a-4a67-c644-c8d5ec9c5de1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-fVqfaFdxgR",
        "outputId": "c146067d-ff8d-4fb3-e439-7106ae7eb732"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec  5 12:01:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXmMzqI1veZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e4e402-b3fb-44c9-9f3c-67bea103d5fb"
      },
      "source": [
        "!pip install git+https://github.com/sybrenstuvel/Python-RVO2.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/sybrenstuvel/Python-RVO2.git\n",
            "  Cloning https://github.com/sybrenstuvel/Python-RVO2.git to /tmp/pip-req-build-28mb6pnn\n",
            "  Running command git clone -q https://github.com/sybrenstuvel/Python-RVO2.git /tmp/pip-req-build-28mb6pnn\n",
            "Building wheels for collected packages: pyrvo2\n",
            "  Building wheel for pyrvo2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrvo2: filename=pyrvo2-0.0.0-cp37-cp37m-linux_x86_64.whl size=208136 sha256=03409258e52f92e5e7ca5d53c10aace5cf7b8103fc547328e562c34fa7222d62\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-57ws3x35/wheels/01/e5/da/4a38f01b99ba7359fc01d9af0dbed31b79cfbaf7ed0dcf6a28\n",
            "Successfully built pyrvo2\n",
            "Installing collected packages: pyrvo2\n",
            "Successfully installed pyrvo2-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2_xLQu5pafE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5144c3-8fdb-4ffc-c721-35ec0887d1c8"
      },
      "source": [
        "!pip install git+https://github.com/svenkreiss/socialforce.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/svenkreiss/socialforce.git\n",
            "  Cloning https://github.com/svenkreiss/socialforce.git to /tmp/pip-req-build-pk13xcxi\n",
            "  Running command git clone -q https://github.com/svenkreiss/socialforce.git /tmp/pip-req-build-pk13xcxi\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from socialforce==0.2.1) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from socialforce==0.2.1) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->socialforce==0.2.1) (3.10.0.2)\n",
            "Building wheels for collected packages: socialforce\n",
            "  Building wheel for socialforce (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for socialforce: filename=socialforce-0.2.1-py3-none-any.whl size=18064 sha256=af03fa4aee23c91de402186953e40ab1790cfa43b6fa1b8c84df8b1fb8947f86\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kt2qjxkw/wheels/c3/2c/0b/a5de11b72e2e084caf077e2bd4c32f50cb463ee059164c1b86\n",
            "Successfully built socialforce\n",
            "Installing collected packages: socialforce\n",
            "Successfully installed socialforce-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z1heuSSovVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0b673d-bf3c-4d7a-ad35-a86d621995b8"
      },
      "source": [
        "!pip install git+https://github.com/vita-epfl/trajnetplusplustools.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/vita-epfl/trajnetplusplustools.git\n",
            "  Cloning https://github.com/vita-epfl/trajnetplusplustools.git to /tmp/pip-req-build-cmunz_cm\n",
            "  Running command git clone -q https://github.com/vita-epfl/trajnetplusplustools.git /tmp/pip-req-build-cmunz_cm\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trajnetplusplustools==0.3.0) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trajnetplusplustools==0.3.0) (1.4.1)\n",
            "Collecting pykalman\n",
            "  Downloading pykalman-0.9.5.tar.gz (228 kB)\n",
            "\u001b[K     |████████████████████████████████| 228 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: trajnetplusplustools, pykalman\n",
            "  Building wheel for trajnetplusplustools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trajnetplusplustools: filename=trajnetplusplustools-0.3.0-py3-none-any.whl size=17669 sha256=a72096f3d3220b3dc7f9838fa7f09fda508c5eb17ef22a88f1938d891cd85931\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wn7wz573/wheels/1c/97/87/a403c722690982355c47d22d001a1e8e5f8ef747bccca37b95\n",
            "  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykalman: filename=pykalman-0.9.5-py3-none-any.whl size=48461 sha256=dbdd25bd8eef7cc39aa45e18564929390cbd377cc4a5afdc096820436e6fd283\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/04/02/2dda6ea59c66d9e685affc8af3a31ad3a5d87b7311689efce6\n",
            "Successfully built trajnetplusplustools pykalman\n",
            "Installing collected packages: pykalman, trajnetplusplustools\n",
            "Successfully installed pykalman-0.9.5 trajnetplusplustools-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTVxqCxOpxBL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "fb8826ac-34c6-4fea-ca24-6a2869a02172"
      },
      "source": [
        "!pip install git+https://github.com/vita-epfl/trajnetplusplusdataset.git"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/vita-epfl/trajnetplusplusdataset.git\n",
            "  Cloning https://github.com/vita-epfl/trajnetplusplusdataset.git to /tmp/pip-req-build-n8gdav29\n",
            "  Running command git clone -q https://github.com/vita-epfl/trajnetplusplusdataset.git /tmp/pip-req-build-n8gdav29\n",
            "Collecting pysparkling\n",
            "  Downloading pysparkling-0.6.1.tar.gz (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trajnetdataset==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: trajnetplusplustools in /usr/local/lib/python3.7/dist-packages (from trajnetdataset==0.1.0) (0.3.0)\n",
            "Collecting boto>=2.36.0\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.15 in /usr/local/lib/python3.7/dist-packages (from pysparkling->trajnetdataset==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from pysparkling->trajnetdataset==0.1.0) (2.23.0)\n",
            "Collecting pytz>=2019.3\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pysparkling->trajnetdataset==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.0->pysparkling->trajnetdataset==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.6.0->pysparkling->trajnetdataset==0.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.6.0->pysparkling->trajnetdataset==0.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.6.0->pysparkling->trajnetdataset==0.1.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.6.0->pysparkling->trajnetdataset==0.1.0) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->trajnetdataset==0.1.0) (1.19.5)\n",
            "Requirement already satisfied: pykalman in /usr/local/lib/python3.7/dist-packages (from trajnetplusplustools->trajnetdataset==0.1.0) (0.9.5)\n",
            "Building wheels for collected packages: trajnetdataset, pysparkling\n",
            "  Building wheel for trajnetdataset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trajnetdataset: filename=trajnetdataset-0.1.0-py3-none-any.whl size=19772 sha256=18585852f69e0f169b6c41a2b37fa129d3cd040462fb7e9e3ebea98e6e34fc52\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qdvohrq1/wheels/6f/50/72/54e0c61e85715d9c0cd7b92e3e8e95ccdb648f9986b7da95dc\n",
            "  Building wheel for pysparkling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysparkling: filename=pysparkling-0.6.1-py3-none-any.whl size=187580 sha256=ccfbf953c631efcc3b6fae1c2163fbb6b5d4734ddfeee7013c2197bc6d7778f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/2e/ac/5336e8ec240e9895bf4f142026f16d0d442af578d339c44aa0\n",
            "Successfully built trajnetdataset pysparkling\n",
            "Installing collected packages: pytz, boto, pysparkling, trajnetdataset\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "Successfully installed boto-2.49.0 pysparkling-0.6.1 pytz-2021.3 trajnetdataset-0.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pytz"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mz2NL-NtR6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95d5fdc-f082-4862-dbf9-3eacd5ffb6b5"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Trajnet++/')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/Trajnet++/\n",
        "\n",
        "# !git clone git+https://github.com/vita-epfl/trajnetplusplusbaselines.git\n",
        "\n",
        "%cd trajnetplusplusbaselines/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Trajnet++\n",
            "/content/drive/MyDrive/Colab Notebooks/Trajnet++/trajnetplusplusbaselines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy7ELRsltWEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3beaa0ea-2dbf-4b02-986a-20b2cb145cab"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_validation.py  \u001b[0m\u001b[01;34mevaluator\u001b[0m/     README.rst  \u001b[01;34mtrajnetbaselines\u001b[0m/\n",
            "\u001b[01;34mDATA_BLOCK\u001b[0m/           get_dest.py    setup.py    \u001b[01;34mtrajnetbaselines.egg-info\u001b[0m/\n",
            "\u001b[01;34mdocs\u001b[0m/                 \u001b[01;34mOUTPUT_BLOCK\u001b[0m/  \u001b[01;34mtests\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRuDonaenip8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8292bebb-0a1c-4be2-d0c7-e8c6ef9234e5"
      },
      "source": [
        "print('==== Starting SGAN Trian ====')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Starting SGAN Trian ====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB25632c0jCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11db566-6169-434a-995c-c2ab07de055c"
      },
      "source": [
        "import torch\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Actual Device:', device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch 1.10.0+cu111 CUDA 11.1\n",
            "Device: cuda:0\n",
            "Actual Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjR4p7DdqLEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63981cdb-a306-43c2-96e0-c16590191a42"
      },
      "source": [
        "!python3 -m trajnetbaselines.sgan.trainer --help"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: trainer.py [-h] [--epochs EPOCHS] [--save_every SAVE_EVERY]\n",
            "                  [--obs_length OBS_LENGTH] [--pred_length PRED_LENGTH]\n",
            "                  [--start_length START_LENGTH] [--batch_size BATCH_SIZE]\n",
            "                  [-o OUTPUT] [--disable-cuda] [--path PATH] [--goals]\n",
            "                  [--loss {L2,pred}]\n",
            "                  [--type {vanilla,occupancy,directional,social,hiddenstatemlp,s_att_fast,directionalmlp,nn,attentionmlp,nn_lstm,traj_pool,nmmp,dir_social}]\n",
            "                  [--sample SAMPLE] [--seed SEED] [--augment]\n",
            "                  [--normalize_scene] [--load-state LOAD_STATE]\n",
            "                  [--load-full-state LOAD_FULL_STATE]\n",
            "                  [--nonstrict-load-state NONSTRICT_LOAD_STATE]\n",
            "                  [--hidden-dim HIDDEN_DIM]\n",
            "                  [--coordinate-embedding-dim COORDINATE_EMBEDDING_DIM]\n",
            "                  [--pool_dim POOL_DIM] [--goal_dim GOAL_DIM]\n",
            "                  [--cell_side CELL_SIDE] [--n N]\n",
            "                  [--layer_dims [LAYER_DIMS [LAYER_DIMS ...]]]\n",
            "                  [--embedding_arch EMBEDDING_ARCH]\n",
            "                  [--pool_constant POOL_CONSTANT] [--norm_pool] [--front]\n",
            "                  [--latent_dim LATENT_DIM] [--norm NORM] [--no_vel]\n",
            "                  [--spatial_dim SPATIAL_DIM] [--vel_dim VEL_DIM]\n",
            "                  [--neigh NEIGH] [--mp_iters MP_ITERS] [--g_steps G_STEPS]\n",
            "                  [--d_steps D_STEPS] [--g_lr G_LR] [--d_lr D_LR]\n",
            "                  [--g_step_size G_STEP_SIZE] [--d_step_size D_STEP_SIZE]\n",
            "                  [--no_noise] [--noise_dim NOISE_DIM]\n",
            "                  [--noise_type {gaussian,uniform}] [--k K]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --epochs EPOCHS       number of epochs\n",
            "  --save_every SAVE_EVERY\n",
            "                        frequency of saving model (in terms of epochs)\n",
            "  --obs_length OBS_LENGTH\n",
            "                        observation length\n",
            "  --pred_length PRED_LENGTH\n",
            "                        prediction length\n",
            "  --start_length START_LENGTH\n",
            "                        starting time step of encoding observation\n",
            "  --batch_size BATCH_SIZE\n",
            "  -o OUTPUT, --output OUTPUT\n",
            "                        output file\n",
            "  --disable-cuda        disable CUDA\n",
            "  --path PATH           glob expression for data files\n",
            "  --goals               flag to consider goals of pedestrians\n",
            "  --loss {L2,pred}      loss objective, L2 loss (L2) and Gaussian loss (pred)\n",
            "  --type {vanilla,occupancy,directional,social,hiddenstatemlp,s_att_fast,directionalmlp,nn,attentionmlp,nn_lstm,traj_pool,nmmp,dir_social}\n",
            "                        type of interaction encoder\n",
            "  --sample SAMPLE       sample ratio when loading train/val scenes\n",
            "  --seed SEED\n",
            "  --augment             perform rotation augmentation\n",
            "  --normalize_scene     rotate scene so primary pedestrian moves northwards at\n",
            "                        end of observation\n",
            "\n",
            "pretraining:\n",
            "  --load-state LOAD_STATE\n",
            "                        load a pickled model state dictionary before training\n",
            "  --load-full-state LOAD_FULL_STATE\n",
            "                        load a pickled full state dictionary before training\n",
            "  --nonstrict-load-state NONSTRICT_LOAD_STATE\n",
            "                        load a pickled state dictionary before training\n",
            "\n",
            "hyperparameters:\n",
            "  --hidden-dim HIDDEN_DIM\n",
            "                        LSTM hidden dimension\n",
            "  --coordinate-embedding-dim COORDINATE_EMBEDDING_DIM\n",
            "                        coordinate embedding dimension\n",
            "  --pool_dim POOL_DIM   output dimension of interaction vector\n",
            "  --goal_dim GOAL_DIM   goal embedding dimension\n",
            "  --cell_side CELL_SIDE\n",
            "                        cell size of real world (in m) for grid-based pooling\n",
            "  --n N                 number of cells per side for grid-based pooling\n",
            "  --layer_dims [LAYER_DIMS [LAYER_DIMS ...]]\n",
            "                        interaction module layer dims for gridbased pooling\n",
            "  --embedding_arch EMBEDDING_ARCH\n",
            "                        interaction encoding arch for gridbased pooling\n",
            "  --pool_constant POOL_CONSTANT\n",
            "                        background value (when cell empty) of gridbased\n",
            "                        pooling\n",
            "  --norm_pool           normalize the scene along direction of movement during\n",
            "                        grid-based pooling\n",
            "  --front               flag to only consider pedestrian in front during grid-\n",
            "                        based pooling\n",
            "  --latent_dim LATENT_DIM\n",
            "                        latent dimension of encoding hidden dimension during\n",
            "                        social pooling\n",
            "  --norm NORM           normalization scheme for input batch during grid-based\n",
            "                        pooling\n",
            "  --no_vel              flag to not consider relative velocity of neighbours\n",
            "  --spatial_dim SPATIAL_DIM\n",
            "                        embedding dimension for relative position\n",
            "  --vel_dim VEL_DIM     embedding dimension for relative velocity\n",
            "  --neigh NEIGH         number of nearest neighbours to consider\n",
            "  --mp_iters MP_ITERS   message passing iterations in NMMP\n",
            "  --g_steps G_STEPS     number of steps of generator training\n",
            "  --d_steps D_STEPS     number of steps of discriminator training\n",
            "  --g_lr G_LR           initial generator learning rate\n",
            "  --d_lr D_LR           initial discriminator learning rate\n",
            "  --g_step_size G_STEP_SIZE\n",
            "                        step_size of generator scheduler\n",
            "  --d_step_size D_STEP_SIZE\n",
            "                        step_size of discriminator scheduler\n",
            "  --no_noise            flag to not add noise (i.e. deterministic model)\n",
            "  --noise_dim NOISE_DIM\n",
            "                        dimension of noise z\n",
            "  --noise_type {gaussian,uniform}\n",
            "                        type of noise to be added\n",
            "  --k K                 number of samples for variety loss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3I7ARg7vsyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7634a7-e3e3-427c-8eee-d6ea5d7c12bb"
      },
      "source": [
        "!python -m trajnetbaselines.sgan.trainer\\\n",
        "  --type directional\\\n",
        "  --augment --d_steps 0 --k 3\\\n",
        "  --output 'iteration-0'\\\n",
        "  --epochs 100\\\n",
        "  --save_every 10\\\n",
        "  # --path eth\\\n",
        "\n",
        "# args.load_state = 'OUTPUT_BLOCK/{}/sgan_goals_{}_{}.pkl'.format(args.path, args.type, args.output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:root:{'type': 'process', 'argv': ['/content/drive/MyDrive/Colab Notebooks/Trajnet++/trajnetplusplusbaselines/trajnetbaselines/sgan/trainer.py', '--type', 'directional', '--augment', '--d_steps', '0', '--k', '3', '--output', 'iteration-0', '--epochs', '100', '--save_every', '10', '--path', 'eth'], 'args': {'epochs': 100, 'save_every': 10, 'obs_length': 9, 'pred_length': 12, 'start_length': 0, 'batch_size': 8, 'output': 'OUTPUT_BLOCK/eth/sgan_directional_iteration-0.pkl', 'disable_cuda': False, 'path': 'eth', 'goals': False, 'loss': 'pred', 'type': 'directional', 'sample': 1.0, 'seed': 42, 'augment': True, 'normalize_scene': False, 'load_state': None, 'load_full_state': None, 'nonstrict_load_state': None, 'hidden_dim': 128, 'coordinate_embedding_dim': 64, 'pool_dim': 256, 'goal_dim': 64, 'cell_side': 0.6, 'n': 12, 'layer_dims': [512], 'embedding_arch': 'one_layer', 'pool_constant': 0, 'norm_pool': False, 'front': False, 'latent_dim': 16, 'norm': 0, 'no_vel': False, 'spatial_dim': 32, 'vel_dim': 32, 'neigh': 4, 'mp_iters': 5, 'g_steps': 1, 'd_steps': 0, 'g_lr': 0.001, 'd_lr': 0.001, 'g_step_size': 10, 'd_step_size': 10, 'no_noise': False, 'noise_dim': 16, 'noise_type': 'gaussian', 'k': 3}, 'version': '0.1.0', 'hostname': 'dc4b4112373f'}\n",
            "Torch 1.10.0+cu111 CUDA 11.1\n",
            "Device: cuda:0\n",
            "Actual Device: cuda:0\n",
            "epoch 0\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 0, 'batch': 79, 'n_batches': 165, 'time': 1.819, 'data_time': 0.001, 'lr': 0.001, 'loss': -1.35}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 0, 'batch': 159, 'n_batches': 165, 'time': 1.865, 'data_time': 0.001, 'lr': 0.001, 'loss': -9.752}\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 1, 'loss': 0.12687, 'time': 37.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 1, 'loss': 0.0, 'test_loss': 0.164, 'time': 3.7}\n",
            "epoch 1\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 1, 'batch': 79, 'n_batches': 165, 'time': 1.75, 'data_time': 0.001, 'lr': 0.001, 'loss': -8.415}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 1, 'batch': 159, 'n_batches': 165, 'time': 1.869, 'data_time': 0.001, 'lr': 0.001, 'loss': -2.891}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 2, 'loss': -1.2437, 'time': 38.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 2, 'loss': 0.0, 'test_loss': -0.728, 'time': 3.7}\n",
            "epoch 2\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 2, 'batch': 79, 'n_batches': 165, 'time': 1.843, 'data_time': 0.001, 'lr': 0.001, 'loss': -12.861}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 2, 'batch': 159, 'n_batches': 165, 'time': 1.707, 'data_time': 0.001, 'lr': 0.001, 'loss': -11.662}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 3, 'loss': -1.4025, 'time': 37.9}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 3, 'loss': 0.0, 'test_loss': 0.254, 'time': 3.7}\n",
            "epoch 3\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 3, 'batch': 79, 'n_batches': 165, 'time': 1.775, 'data_time': 0.001, 'lr': 0.001, 'loss': -14.033}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 3, 'batch': 159, 'n_batches': 165, 'time': 1.75, 'data_time': 0.001, 'lr': 0.001, 'loss': -15.06}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 4, 'loss': -1.6831, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 4, 'loss': 0.0, 'test_loss': 0.592, 'time': 3.7}\n",
            "epoch 4\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 4, 'batch': 79, 'n_batches': 165, 'time': 1.908, 'data_time': 0.001, 'lr': 0.001, 'loss': -11.539}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 4, 'batch': 159, 'n_batches': 165, 'time': 1.769, 'data_time': 0.001, 'lr': 0.001, 'loss': -15.283}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 5, 'loss': -1.71237, 'time': 37.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 5, 'loss': 0.0, 'test_loss': -0.071, 'time': 3.6}\n",
            "epoch 5\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 5, 'batch': 79, 'n_batches': 165, 'time': 1.729, 'data_time': 0.001, 'lr': 0.001, 'loss': -8.536}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 5, 'batch': 159, 'n_batches': 165, 'time': 1.898, 'data_time': 0.001, 'lr': 0.001, 'loss': -13.901}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 6, 'loss': -1.66152, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 6, 'loss': 0.0, 'test_loss': -0.294, 'time': 3.7}\n",
            "epoch 6\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 6, 'batch': 79, 'n_batches': 165, 'time': 1.749, 'data_time': 0.001, 'lr': 0.001, 'loss': -11.275}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 6, 'batch': 159, 'n_batches': 165, 'time': 1.869, 'data_time': 0.001, 'lr': 0.001, 'loss': -10.985}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 7, 'loss': -1.73768, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 7, 'loss': 0.0, 'test_loss': -0.077, 'time': 3.7}\n",
            "epoch 7\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 7, 'batch': 79, 'n_batches': 165, 'time': 2.03, 'data_time': 0.001, 'lr': 0.001, 'loss': -13.127}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 7, 'batch': 159, 'n_batches': 165, 'time': 1.715, 'data_time': 0.001, 'lr': 0.001, 'loss': -12.706}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 8, 'loss': -1.71033, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 8, 'loss': 0.0, 'test_loss': -0.571, 'time': 3.7}\n",
            "epoch 8\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 8, 'batch': 79, 'n_batches': 165, 'time': 1.888, 'data_time': 0.001, 'lr': 0.001, 'loss': -14.746}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 8, 'batch': 159, 'n_batches': 165, 'time': 1.823, 'data_time': 0.001, 'lr': 0.001, 'loss': -14.827}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 9, 'loss': -1.77574, 'time': 37.9}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 9, 'loss': 0.0, 'test_loss': 1.029, 'time': 3.7}\n",
            "epoch 9\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 9, 'batch': 79, 'n_batches': 165, 'time': 1.78, 'data_time': 0.001, 'lr': 0.001, 'loss': -15.71}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 9, 'batch': 159, 'n_batches': 165, 'time': 1.852, 'data_time': 0.001, 'lr': 0.001, 'loss': -16.629}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 10, 'loss': -1.74323, 'time': 37.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 10, 'loss': 0.0, 'test_loss': -0.274, 'time': 3.6}\n",
            "epoch 10\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 10, 'batch': 79, 'n_batches': 165, 'time': 1.904, 'data_time': 0.001, 'lr': 0.0001, 'loss': -14.11}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 10, 'batch': 159, 'n_batches': 165, 'time': 1.725, 'data_time': 0.001, 'lr': 0.0001, 'loss': -17.262}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 11, 'loss': -1.95704, 'time': 37.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 11, 'loss': 0.0, 'test_loss': 0.037, 'time': 3.8}\n",
            "epoch 11\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 11, 'batch': 79, 'n_batches': 165, 'time': 1.716, 'data_time': 0.001, 'lr': 0.0001, 'loss': -13.295}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 11, 'batch': 159, 'n_batches': 165, 'time': 1.992, 'data_time': 0.001, 'lr': 0.0001, 'loss': -15.806}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 12, 'loss': -2.06205, 'time': 38.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 12, 'loss': 0.0, 'test_loss': -0.215, 'time': 3.6}\n",
            "epoch 12\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 12, 'batch': 79, 'n_batches': 165, 'time': 1.809, 'data_time': 0.001, 'lr': 0.0001, 'loss': -16.778}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 12, 'batch': 159, 'n_batches': 165, 'time': 1.818, 'data_time': 0.001, 'lr': 0.0001, 'loss': -17.075}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 13, 'loss': -2.09571, 'time': 37.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 13, 'loss': 0.0, 'test_loss': -0.282, 'time': 3.7}\n",
            "epoch 13\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 13, 'batch': 79, 'n_batches': 165, 'time': 2.113, 'data_time': 0.001, 'lr': 0.0001, 'loss': -14.577}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 13, 'batch': 159, 'n_batches': 165, 'time': 1.912, 'data_time': 0.001, 'lr': 0.0001, 'loss': -18.011}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 14, 'loss': -2.12658, 'time': 38.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 14, 'loss': 0.0, 'test_loss': -0.063, 'time': 3.7}\n",
            "epoch 14\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 14, 'batch': 79, 'n_batches': 165, 'time': 1.741, 'data_time': 0.001, 'lr': 0.0001, 'loss': -16.058}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 14, 'batch': 159, 'n_batches': 165, 'time': 1.959, 'data_time': 0.001, 'lr': 0.0001, 'loss': -15.9}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 15, 'loss': -2.15795, 'time': 37.9}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 15, 'loss': 0.0, 'test_loss': 0.08, 'time': 3.6}\n",
            "epoch 15\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 15, 'batch': 79, 'n_batches': 165, 'time': 1.742, 'data_time': 0.001, 'lr': 0.0001, 'loss': -15.505}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 15, 'batch': 159, 'n_batches': 165, 'time': 1.807, 'data_time': 0.001, 'lr': 0.0001, 'loss': -19.374}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 16, 'loss': -2.13084, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 16, 'loss': 0.0, 'test_loss': 0.012, 'time': 3.8}\n",
            "epoch 16\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 16, 'batch': 79, 'n_batches': 165, 'time': 1.788, 'data_time': 0.001, 'lr': 0.0001, 'loss': -19.892}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 16, 'batch': 159, 'n_batches': 165, 'time': 1.84, 'data_time': 0.001, 'lr': 0.0001, 'loss': -17.751}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 17, 'loss': -2.18153, 'time': 37.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 17, 'loss': 0.0, 'test_loss': -0.007, 'time': 3.7}\n",
            "epoch 17\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 17, 'batch': 79, 'n_batches': 165, 'time': 1.861, 'data_time': 0.001, 'lr': 0.0001, 'loss': -18.91}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 17, 'batch': 159, 'n_batches': 165, 'time': 1.846, 'data_time': 0.001, 'lr': 0.0001, 'loss': -18.502}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 18, 'loss': -2.21853, 'time': 37.9}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 18, 'loss': 0.0, 'test_loss': 0.212, 'time': 3.7}\n",
            "epoch 18\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 18, 'batch': 79, 'n_batches': 165, 'time': 1.972, 'data_time': 0.001, 'lr': 0.0001, 'loss': -19.497}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 18, 'batch': 159, 'n_batches': 165, 'time': 1.905, 'data_time': 0.002, 'lr': 0.0001, 'loss': -19.264}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 19, 'loss': -2.27419, 'time': 38.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 19, 'loss': 0.0, 'test_loss': 0.142, 'time': 3.8}\n",
            "epoch 19\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 19, 'batch': 79, 'n_batches': 165, 'time': 1.767, 'data_time': 0.001, 'lr': 0.0001, 'loss': -19.555}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 19, 'batch': 159, 'n_batches': 165, 'time': 1.832, 'data_time': 0.001, 'lr': 0.0001, 'loss': -17.112}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 20, 'loss': -2.249, 'time': 37.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 20, 'loss': 0.0, 'test_loss': 0.173, 'time': 3.7}\n",
            "epoch 20\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 20, 'batch': 79, 'n_batches': 165, 'time': 1.843, 'data_time': 0.001, 'lr': 1e-05, 'loss': -16.585}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 20, 'batch': 159, 'n_batches': 165, 'time': 1.843, 'data_time': 0.001, 'lr': 1e-05, 'loss': -21.223}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 21, 'loss': -2.27107, 'time': 37.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 21, 'loss': 0.0, 'test_loss': 0.099, 'time': 3.6}\n",
            "epoch 21\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 21, 'batch': 79, 'n_batches': 165, 'time': 1.738, 'data_time': 0.001, 'lr': 1e-05, 'loss': -21.253}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 21, 'batch': 159, 'n_batches': 165, 'time': 1.803, 'data_time': 0.001, 'lr': 1e-05, 'loss': -15.929}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 22, 'loss': -2.27818, 'time': 37.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 22, 'loss': 0.0, 'test_loss': 0.198, 'time': 3.7}\n",
            "epoch 22\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 22, 'batch': 79, 'n_batches': 165, 'time': 1.792, 'data_time': 0.001, 'lr': 1e-05, 'loss': -19.266}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 22, 'batch': 159, 'n_batches': 165, 'time': 1.807, 'data_time': 0.001, 'lr': 1e-05, 'loss': -17.837}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 23, 'loss': -2.31972, 'time': 37.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 23, 'loss': 0.0, 'test_loss': 0.092, 'time': 3.6}\n",
            "epoch 23\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 23, 'batch': 79, 'n_batches': 165, 'time': 1.817, 'data_time': 0.001, 'lr': 1e-05, 'loss': -18.863}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 23, 'batch': 159, 'n_batches': 165, 'time': 1.655, 'data_time': 0.001, 'lr': 1e-05, 'loss': -21.921}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 24, 'loss': -2.26855, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 24, 'loss': 0.0, 'test_loss': -0.052, 'time': 3.6}\n",
            "epoch 24\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 24, 'batch': 79, 'n_batches': 165, 'time': 1.774, 'data_time': 0.001, 'lr': 1e-05, 'loss': -19.08}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 24, 'batch': 159, 'n_batches': 165, 'time': 1.826, 'data_time': 0.001, 'lr': 1e-05, 'loss': -17.631}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 25, 'loss': -2.29469, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 25, 'loss': 0.0, 'test_loss': 0.135, 'time': 3.7}\n",
            "epoch 25\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 25, 'batch': 79, 'n_batches': 165, 'time': 1.645, 'data_time': 0.001, 'lr': 1e-05, 'loss': -20.961}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 25, 'batch': 159, 'n_batches': 165, 'time': 1.75, 'data_time': 0.001, 'lr': 1e-05, 'loss': -19.51}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 26, 'loss': -2.27481, 'time': 36.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 26, 'loss': 0.0, 'test_loss': 0.236, 'time': 3.6}\n",
            "epoch 26\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 26, 'batch': 79, 'n_batches': 165, 'time': 1.788, 'data_time': 0.001, 'lr': 1e-05, 'loss': -16.766}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 26, 'batch': 159, 'n_batches': 165, 'time': 1.876, 'data_time': 0.001, 'lr': 1e-05, 'loss': -17.939}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 27, 'loss': -2.30227, 'time': 37.2}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 27, 'loss': 0.0, 'test_loss': 0.004, 'time': 3.6}\n",
            "epoch 27\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 27, 'batch': 79, 'n_batches': 165, 'time': 1.823, 'data_time': 0.001, 'lr': 1e-05, 'loss': -13.596}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 27, 'batch': 159, 'n_batches': 165, 'time': 1.778, 'data_time': 0.001, 'lr': 1e-05, 'loss': -19.522}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 28, 'loss': -2.27231, 'time': 36.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 28, 'loss': 0.0, 'test_loss': 0.072, 'time': 3.5}\n",
            "epoch 28\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 28, 'batch': 79, 'n_batches': 165, 'time': 1.712, 'data_time': 0.001, 'lr': 1e-05, 'loss': -18.779}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 28, 'batch': 159, 'n_batches': 165, 'time': 1.849, 'data_time': 0.001, 'lr': 1e-05, 'loss': -20.208}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 29, 'loss': -2.33028, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 29, 'loss': 0.0, 'test_loss': 0.279, 'time': 3.6}\n",
            "epoch 29\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 29, 'batch': 79, 'n_batches': 165, 'time': 1.792, 'data_time': 0.001, 'lr': 1e-05, 'loss': -20.355}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 29, 'batch': 159, 'n_batches': 165, 'time': 1.877, 'data_time': 0.001, 'lr': 1e-05, 'loss': -19.247}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 30, 'loss': -2.23106, 'time': 37.2}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 30, 'loss': 0.0, 'test_loss': 0.317, 'time': 3.6}\n",
            "epoch 30\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 30, 'batch': 79, 'n_batches': 165, 'time': 1.919, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -15.961}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 30, 'batch': 159, 'n_batches': 165, 'time': 1.774, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -15.783}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 31, 'loss': -2.26352, 'time': 37.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 31, 'loss': 0.0, 'test_loss': 0.107, 'time': 3.6}\n",
            "epoch 31\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 31, 'batch': 79, 'n_batches': 165, 'time': 1.728, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -20.151}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 31, 'batch': 159, 'n_batches': 165, 'time': 1.85, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -20.207}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 32, 'loss': -2.26568, 'time': 36.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 32, 'loss': 0.0, 'test_loss': 0.212, 'time': 3.6}\n",
            "epoch 32\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 32, 'batch': 79, 'n_batches': 165, 'time': 1.964, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -17.418}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 32, 'batch': 159, 'n_batches': 165, 'time': 1.851, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -19.491}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 33, 'loss': -2.30327, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 33, 'loss': 0.0, 'test_loss': 0.288, 'time': 3.6}\n",
            "epoch 33\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 33, 'batch': 79, 'n_batches': 165, 'time': 1.775, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -17.996}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 33, 'batch': 159, 'n_batches': 165, 'time': 1.833, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -16.036}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 34, 'loss': -2.28905, 'time': 36.9}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 34, 'loss': 0.0, 'test_loss': 0.22, 'time': 3.7}\n",
            "epoch 34\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 34, 'batch': 79, 'n_batches': 165, 'time': 1.762, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -19.395}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 34, 'batch': 159, 'n_batches': 165, 'time': 1.916, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -17.5}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 35, 'loss': -2.29521, 'time': 37.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 35, 'loss': 0.0, 'test_loss': 0.26, 'time': 3.7}\n",
            "epoch 35\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 35, 'batch': 79, 'n_batches': 165, 'time': 1.81, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -16.89}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 35, 'batch': 159, 'n_batches': 165, 'time': 1.825, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -17.085}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 36, 'loss': -2.30982, 'time': 36.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 36, 'loss': 0.0, 'test_loss': 0.155, 'time': 3.5}\n",
            "epoch 36\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 36, 'batch': 79, 'n_batches': 165, 'time': 1.661, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -19.953}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 36, 'batch': 159, 'n_batches': 165, 'time': 1.805, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -19.273}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 37, 'loss': -2.28818, 'time': 36.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 37, 'loss': 0.0, 'test_loss': 0.352, 'time': 3.6}\n",
            "epoch 37\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 37, 'batch': 79, 'n_batches': 165, 'time': 1.671, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -18.577}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 37, 'batch': 159, 'n_batches': 165, 'time': 1.787, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -18.84}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 38, 'loss': -2.32451, 'time': 36.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 38, 'loss': 0.0, 'test_loss': 0.022, 'time': 3.7}\n",
            "epoch 38\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 38, 'batch': 79, 'n_batches': 165, 'time': 1.694, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -18.696}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 38, 'batch': 159, 'n_batches': 165, 'time': 1.754, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -18.803}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 39, 'loss': -2.30077, 'time': 36.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 39, 'loss': 0.0, 'test_loss': 0.483, 'time': 3.5}\n",
            "epoch 39\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 39, 'batch': 79, 'n_batches': 165, 'time': 1.8, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -20.432}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 39, 'batch': 159, 'n_batches': 165, 'time': 1.646, 'data_time': 0.001, 'lr': 1.0000000000000002e-06, 'loss': -18.773}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 40, 'loss': -2.30729, 'time': 36.2}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 40, 'loss': 0.0, 'test_loss': 0.294, 'time': 3.5}\n",
            "epoch 40\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 40, 'batch': 79, 'n_batches': 165, 'time': 1.807, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -19.699}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 40, 'batch': 159, 'n_batches': 165, 'time': 1.813, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -19.926}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 41, 'loss': -2.32983, 'time': 36.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 41, 'loss': 0.0, 'test_loss': 0.235, 'time': 3.7}\n",
            "epoch 41\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 41, 'batch': 79, 'n_batches': 165, 'time': 1.683, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -18.431}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 41, 'batch': 159, 'n_batches': 165, 'time': 1.664, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -18.716}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 42, 'loss': -2.28018, 'time': 36.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 42, 'loss': 0.0, 'test_loss': 0.166, 'time': 3.6}\n",
            "epoch 42\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 42, 'batch': 79, 'n_batches': 165, 'time': 1.7, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -15.781}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 42, 'batch': 159, 'n_batches': 165, 'time': 1.819, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -18.654}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 43, 'loss': -2.25226, 'time': 36.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 43, 'loss': 0.0, 'test_loss': 0.29, 'time': 3.5}\n",
            "epoch 43\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 43, 'batch': 79, 'n_batches': 165, 'time': 1.708, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -17.428}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 43, 'batch': 159, 'n_batches': 165, 'time': 1.728, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -19.228}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 44, 'loss': -2.29708, 'time': 36.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 44, 'loss': 0.0, 'test_loss': 0.251, 'time': 3.5}\n",
            "epoch 44\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 44, 'batch': 79, 'n_batches': 165, 'time': 1.948, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -17.591}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 44, 'batch': 159, 'n_batches': 165, 'time': 1.749, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -14.313}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 45, 'loss': -2.23089, 'time': 36.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 45, 'loss': 0.0, 'test_loss': 0.208, 'time': 3.5}\n",
            "epoch 45\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 45, 'batch': 79, 'n_batches': 165, 'time': 1.754, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -15.588}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 45, 'batch': 159, 'n_batches': 165, 'time': 1.633, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -20.154}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 46, 'loss': -2.28271, 'time': 36.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 46, 'loss': 0.0, 'test_loss': 0.342, 'time': 3.6}\n",
            "epoch 46\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 46, 'batch': 79, 'n_batches': 165, 'time': 1.765, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -16.176}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 46, 'batch': 159, 'n_batches': 165, 'time': 1.751, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -18.188}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 47, 'loss': -2.26243, 'time': 36.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 47, 'loss': 0.0, 'test_loss': 0.225, 'time': 3.6}\n",
            "epoch 47\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 47, 'batch': 79, 'n_batches': 165, 'time': 1.767, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -13.815}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 47, 'batch': 159, 'n_batches': 165, 'time': 1.862, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -19.139}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 48, 'loss': -2.2987, 'time': 36.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 48, 'loss': 0.0, 'test_loss': 0.357, 'time': 3.6}\n",
            "epoch 48\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 48, 'batch': 79, 'n_batches': 165, 'time': 1.763, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -19.371}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 48, 'batch': 159, 'n_batches': 165, 'time': 1.761, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -20.122}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 49, 'loss': -2.30613, 'time': 37.1}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 49, 'loss': 0.0, 'test_loss': 0.167, 'time': 3.6}\n",
            "epoch 49\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 49, 'batch': 79, 'n_batches': 165, 'time': 1.778, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -17.862}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 49, 'batch': 159, 'n_batches': 165, 'time': 1.686, 'data_time': 0.001, 'lr': 1.0000000000000002e-07, 'loss': -19.121}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 50, 'loss': -2.33108, 'time': 37.2}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 50, 'loss': 0.0, 'test_loss': 0.211, 'time': 3.6}\n",
            "epoch 50\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 50, 'batch': 79, 'n_batches': 165, 'time': 1.749, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -18.919}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 50, 'batch': 159, 'n_batches': 165, 'time': 1.664, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -19.389}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 51, 'loss': -2.26603, 'time': 37.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 51, 'loss': 0.0, 'test_loss': 0.025, 'time': 3.7}\n",
            "epoch 51\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 51, 'batch': 79, 'n_batches': 165, 'time': 1.875, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -12.065}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 51, 'batch': 159, 'n_batches': 165, 'time': 1.658, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -20.353}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 52, 'loss': -2.29558, 'time': 37.1}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 52, 'loss': 0.0, 'test_loss': 0.133, 'time': 3.7}\n",
            "epoch 52\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 52, 'batch': 79, 'n_batches': 165, 'time': 1.77, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -16.866}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 52, 'batch': 159, 'n_batches': 165, 'time': 1.64, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -19.417}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 53, 'loss': -2.30569, 'time': 37.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 53, 'loss': 0.0, 'test_loss': 0.215, 'time': 3.7}\n",
            "epoch 53\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 53, 'batch': 79, 'n_batches': 165, 'time': 1.637, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -19.812}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 53, 'batch': 159, 'n_batches': 165, 'time': 1.799, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -17.999}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 54, 'loss': -2.26655, 'time': 36.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 54, 'loss': 0.0, 'test_loss': 0.299, 'time': 3.6}\n",
            "epoch 54\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 54, 'batch': 79, 'n_batches': 165, 'time': 1.854, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -16.485}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 54, 'batch': 159, 'n_batches': 165, 'time': 1.945, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -19.919}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 55, 'loss': -2.26822, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 55, 'loss': 0.0, 'test_loss': 0.338, 'time': 3.8}\n",
            "epoch 55\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 55, 'batch': 79, 'n_batches': 165, 'time': 1.714, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -16.786}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 55, 'batch': 159, 'n_batches': 165, 'time': 1.725, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -16.113}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 56, 'loss': -2.28237, 'time': 37.1}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 56, 'loss': 0.0, 'test_loss': 0.014, 'time': 3.6}\n",
            "epoch 56\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 56, 'batch': 79, 'n_batches': 165, 'time': 1.732, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -21.994}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 56, 'batch': 159, 'n_batches': 165, 'time': 1.704, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -17.86}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 57, 'loss': -2.29472, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 57, 'loss': 0.0, 'test_loss': 0.301, 'time': 3.6}\n",
            "epoch 57\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 57, 'batch': 79, 'n_batches': 165, 'time': 1.7, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -21.989}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 57, 'batch': 159, 'n_batches': 165, 'time': 1.813, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -17.634}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 58, 'loss': -2.31119, 'time': 37.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 58, 'loss': 0.0, 'test_loss': 0.285, 'time': 3.7}\n",
            "epoch 58\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 58, 'batch': 79, 'n_batches': 165, 'time': 1.817, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -19.403}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 58, 'batch': 159, 'n_batches': 165, 'time': 1.75, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -20.726}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 59, 'loss': -2.28902, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 59, 'loss': 0.0, 'test_loss': 0.115, 'time': 3.6}\n",
            "epoch 59\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 59, 'batch': 79, 'n_batches': 165, 'time': 1.818, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -20.525}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 59, 'batch': 159, 'n_batches': 165, 'time': 1.75, 'data_time': 0.001, 'lr': 1.0000000000000004e-08, 'loss': -17.972}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 60, 'loss': -2.31508, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 60, 'loss': 0.0, 'test_loss': 0.219, 'time': 3.6}\n",
            "epoch 60\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 60, 'batch': 79, 'n_batches': 165, 'time': 1.829, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -14.011}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 60, 'batch': 159, 'n_batches': 165, 'time': 1.944, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -20.528}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 61, 'loss': -2.28048, 'time': 37.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 61, 'loss': 0.0, 'test_loss': 0.017, 'time': 3.7}\n",
            "epoch 61\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 61, 'batch': 79, 'n_batches': 165, 'time': 1.74, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -12.918}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 61, 'batch': 159, 'n_batches': 165, 'time': 1.838, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -16.654}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 62, 'loss': -2.26537, 'time': 37.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 62, 'loss': 0.0, 'test_loss': 0.176, 'time': 3.6}\n",
            "epoch 62\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 62, 'batch': 79, 'n_batches': 165, 'time': 1.777, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -19.247}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 62, 'batch': 159, 'n_batches': 165, 'time': 1.664, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -19.914}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 63, 'loss': -2.30123, 'time': 37.2}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 63, 'loss': 0.0, 'test_loss': 0.291, 'time': 3.6}\n",
            "epoch 63\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 63, 'batch': 79, 'n_batches': 165, 'time': 1.846, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -14.65}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 63, 'batch': 159, 'n_batches': 165, 'time': 1.745, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -18.371}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 64, 'loss': -2.32268, 'time': 37.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 64, 'loss': 0.0, 'test_loss': 0.344, 'time': 3.6}\n",
            "epoch 64\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 64, 'batch': 79, 'n_batches': 165, 'time': 1.828, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -12.017}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 64, 'batch': 159, 'n_batches': 165, 'time': 1.778, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -20.8}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 65, 'loss': -2.2587, 'time': 36.9}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 65, 'loss': 0.0, 'test_loss': 0.147, 'time': 3.6}\n",
            "epoch 65\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 65, 'batch': 79, 'n_batches': 165, 'time': 1.718, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -18.354}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 65, 'batch': 159, 'n_batches': 165, 'time': 1.751, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -20.603}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 66, 'loss': -2.30166, 'time': 36.8}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 66, 'loss': 0.0, 'test_loss': 0.417, 'time': 3.6}\n",
            "epoch 66\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 66, 'batch': 79, 'n_batches': 165, 'time': 1.723, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -18.099}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 66, 'batch': 159, 'n_batches': 165, 'time': 1.889, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -17.22}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 67, 'loss': -2.3183, 'time': 36.9}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 67, 'loss': 0.0, 'test_loss': 0.345, 'time': 3.6}\n",
            "epoch 67\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 67, 'batch': 79, 'n_batches': 165, 'time': 1.807, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -18.02}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 67, 'batch': 159, 'n_batches': 165, 'time': 1.661, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -20.832}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 68, 'loss': -2.30339, 'time': 36.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 68, 'loss': 0.0, 'test_loss': 0.31, 'time': 3.5}\n",
            "epoch 68\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 68, 'batch': 79, 'n_batches': 165, 'time': 1.653, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -19.301}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 68, 'batch': 159, 'n_batches': 165, 'time': 1.863, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -17.266}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 69, 'loss': -2.2922, 'time': 36.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 69, 'loss': 0.0, 'test_loss': 0.133, 'time': 3.6}\n",
            "epoch 69\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 69, 'batch': 79, 'n_batches': 165, 'time': 1.782, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -19.223}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 69, 'batch': 159, 'n_batches': 165, 'time': 1.895, 'data_time': 0.001, 'lr': 1.0000000000000005e-09, 'loss': -18.646}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 70, 'loss': -2.28213, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 70, 'loss': 0.0, 'test_loss': 0.22, 'time': 3.6}\n",
            "epoch 70\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 70, 'batch': 79, 'n_batches': 165, 'time': 1.752, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -18.856}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 70, 'batch': 159, 'n_batches': 165, 'time': 1.82, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -14.999}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 71, 'loss': -2.30485, 'time': 37.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 71, 'loss': 0.0, 'test_loss': 0.199, 'time': 3.7}\n",
            "epoch 71\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 71, 'batch': 79, 'n_batches': 165, 'time': 1.718, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -19.502}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 71, 'batch': 159, 'n_batches': 165, 'time': 1.693, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -19.491}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 72, 'loss': -2.29253, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 72, 'loss': 0.0, 'test_loss': 0.156, 'time': 3.7}\n",
            "epoch 72\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 72, 'batch': 79, 'n_batches': 165, 'time': 1.773, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -17.585}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 72, 'batch': 159, 'n_batches': 165, 'time': 1.736, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -21.192}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 73, 'loss': -2.28499, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 73, 'loss': 0.0, 'test_loss': 0.254, 'time': 3.6}\n",
            "epoch 73\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 73, 'batch': 79, 'n_batches': 165, 'time': 1.77, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -21.678}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 73, 'batch': 159, 'n_batches': 165, 'time': 1.839, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -18.183}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 74, 'loss': -2.33234, 'time': 37.1}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 74, 'loss': 0.0, 'test_loss': 0.235, 'time': 3.6}\n",
            "epoch 74\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 74, 'batch': 79, 'n_batches': 165, 'time': 1.719, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -17.03}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 74, 'batch': 159, 'n_batches': 165, 'time': 1.963, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -16.223}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 75, 'loss': -2.27434, 'time': 37.2}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 75, 'loss': 0.0, 'test_loss': 0.273, 'time': 3.6}\n",
            "epoch 75\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 75, 'batch': 79, 'n_batches': 165, 'time': 1.834, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -18.882}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 75, 'batch': 159, 'n_batches': 165, 'time': 1.779, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -20.809}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 76, 'loss': -2.29526, 'time': 37.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 76, 'loss': 0.0, 'test_loss': 0.022, 'time': 3.6}\n",
            "epoch 76\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 76, 'batch': 79, 'n_batches': 165, 'time': 1.744, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -18.761}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 76, 'batch': 159, 'n_batches': 165, 'time': 1.844, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -18.178}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 77, 'loss': -2.30882, 'time': 37.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 77, 'loss': 0.0, 'test_loss': 0.255, 'time': 3.6}\n",
            "epoch 77\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 77, 'batch': 79, 'n_batches': 165, 'time': 1.69, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -20.494}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 77, 'batch': 159, 'n_batches': 165, 'time': 1.964, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -20.182}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 78, 'loss': -2.2773, 'time': 37.2}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 78, 'loss': 0.0, 'test_loss': 0.18, 'time': 3.6}\n",
            "epoch 78\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 78, 'batch': 79, 'n_batches': 165, 'time': 1.853, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -18.745}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 78, 'batch': 159, 'n_batches': 165, 'time': 1.73, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -16.725}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 79, 'loss': -2.33589, 'time': 36.9}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 79, 'loss': 0.0, 'test_loss': -0.036, 'time': 3.7}\n",
            "epoch 79\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 79, 'batch': 79, 'n_batches': 165, 'time': 1.753, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -18.89}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 79, 'batch': 159, 'n_batches': 165, 'time': 1.838, 'data_time': 0.001, 'lr': 1.0000000000000006e-10, 'loss': -18.262}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 80, 'loss': -2.33012, 'time': 37.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 80, 'loss': 0.0, 'test_loss': 0.04, 'time': 3.7}\n",
            "epoch 80\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 80, 'batch': 79, 'n_batches': 165, 'time': 1.676, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.419}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 80, 'batch': 159, 'n_batches': 165, 'time': 1.847, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.461}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 81, 'loss': -2.33375, 'time': 37.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 81, 'loss': 0.0, 'test_loss': 0.236, 'time': 3.7}\n",
            "epoch 81\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 81, 'batch': 79, 'n_batches': 165, 'time': 1.717, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.747}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 81, 'batch': 159, 'n_batches': 165, 'time': 1.735, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -19.639}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 82, 'loss': -2.27657, 'time': 37.1}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 82, 'loss': 0.0, 'test_loss': 0.266, 'time': 3.5}\n",
            "epoch 82\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 82, 'batch': 79, 'n_batches': 165, 'time': 1.994, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -20.372}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 82, 'batch': 159, 'n_batches': 165, 'time': 1.722, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.357}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 83, 'loss': -2.29238, 'time': 37.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 83, 'loss': 0.0, 'test_loss': 0.182, 'time': 3.7}\n",
            "epoch 83\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 83, 'batch': 79, 'n_batches': 165, 'time': 1.761, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.611}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 83, 'batch': 159, 'n_batches': 165, 'time': 1.819, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.101}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 84, 'loss': -2.30529, 'time': 37.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 84, 'loss': 0.0, 'test_loss': 0.201, 'time': 3.7}\n",
            "epoch 84\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 84, 'batch': 79, 'n_batches': 165, 'time': 1.863, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -20.269}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 84, 'batch': 159, 'n_batches': 165, 'time': 1.915, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.812}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 85, 'loss': -2.28786, 'time': 37.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 85, 'loss': 0.0, 'test_loss': 0.217, 'time': 3.8}\n",
            "epoch 85\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 85, 'batch': 79, 'n_batches': 165, 'time': 1.899, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -19.163}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 85, 'batch': 159, 'n_batches': 165, 'time': 1.816, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -16.288}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 86, 'loss': -2.33112, 'time': 38.1}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 86, 'loss': 0.0, 'test_loss': 0.213, 'time': 3.7}\n",
            "epoch 86\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 86, 'batch': 79, 'n_batches': 165, 'time': 1.869, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -16.803}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 86, 'batch': 159, 'n_batches': 165, 'time': 1.843, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.53}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 87, 'loss': -2.3111, 'time': 38.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 87, 'loss': 0.0, 'test_loss': 0.12, 'time': 3.7}\n",
            "epoch 87\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 87, 'batch': 79, 'n_batches': 165, 'time': 1.749, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -20.142}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 87, 'batch': 159, 'n_batches': 165, 'time': 1.904, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -19.94}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 88, 'loss': -2.29103, 'time': 37.7}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 88, 'loss': 0.0, 'test_loss': 0.31, 'time': 3.8}\n",
            "epoch 88\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 88, 'batch': 79, 'n_batches': 165, 'time': 1.973, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -15.113}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 88, 'batch': 159, 'n_batches': 165, 'time': 1.902, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -16.263}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 89, 'loss': -2.28362, 'time': 37.6}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 89, 'loss': 0.0, 'test_loss': 0.374, 'time': 3.6}\n",
            "epoch 89\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 89, 'batch': 79, 'n_batches': 165, 'time': 1.89, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -19.508}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 89, 'batch': 159, 'n_batches': 165, 'time': 1.697, 'data_time': 0.001, 'lr': 1.0000000000000006e-11, 'loss': -18.894}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 90, 'loss': -2.30332, 'time': 37.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 90, 'loss': 0.0, 'test_loss': 0.228, 'time': 3.7}\n",
            "epoch 90\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 90, 'batch': 79, 'n_batches': 165, 'time': 1.933, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -19.229}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 90, 'batch': 159, 'n_batches': 165, 'time': 1.802, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -16.981}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 91, 'loss': -2.26935, 'time': 37.3}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 91, 'loss': 0.0, 'test_loss': 0.246, 'time': 3.7}\n",
            "epoch 91\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 91, 'batch': 79, 'n_batches': 165, 'time': 1.913, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -17.467}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 91, 'batch': 159, 'n_batches': 165, 'time': 1.938, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -17.085}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 92, 'loss': -2.32521, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 92, 'loss': 0.0, 'test_loss': 0.261, 'time': 3.6}\n",
            "epoch 92\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 92, 'batch': 79, 'n_batches': 165, 'time': 1.762, 'data_time': 0.002, 'lr': 1.0000000000000006e-12, 'loss': -17.378}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 92, 'batch': 159, 'n_batches': 165, 'time': 1.776, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -20.685}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 93, 'loss': -2.31059, 'time': 37.0}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 93, 'loss': 0.0, 'test_loss': 0.207, 'time': 3.6}\n",
            "epoch 93\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 93, 'batch': 79, 'n_batches': 165, 'time': 1.874, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -17.087}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 93, 'batch': 159, 'n_batches': 165, 'time': 1.833, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -17.781}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 94, 'loss': -2.26168, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 94, 'loss': 0.0, 'test_loss': 0.287, 'time': 3.6}\n",
            "epoch 94\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 94, 'batch': 79, 'n_batches': 165, 'time': 1.778, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -19.095}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 94, 'batch': 159, 'n_batches': 165, 'time': 1.74, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -17.582}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 95, 'loss': -2.30315, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 95, 'loss': 0.0, 'test_loss': 0.147, 'time': 3.6}\n",
            "epoch 95\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 95, 'batch': 79, 'n_batches': 165, 'time': 1.79, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -19.197}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 95, 'batch': 159, 'n_batches': 165, 'time': 1.778, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -19.997}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 96, 'loss': -2.31368, 'time': 37.1}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 96, 'loss': 0.0, 'test_loss': 0.18, 'time': 3.7}\n",
            "epoch 96\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 96, 'batch': 79, 'n_batches': 165, 'time': 1.912, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -16.998}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 96, 'batch': 159, 'n_batches': 165, 'time': 1.756, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -20.415}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 97, 'loss': -2.31022, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 97, 'loss': 0.0, 'test_loss': 0.233, 'time': 3.6}\n",
            "epoch 97\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 97, 'batch': 79, 'n_batches': 165, 'time': 1.91, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -17.549}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 97, 'batch': 159, 'n_batches': 165, 'time': 1.831, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -21.373}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 98, 'loss': -2.29185, 'time': 37.4}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 98, 'loss': 0.0, 'test_loss': 0.315, 'time': 3.7}\n",
            "epoch 98\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 98, 'batch': 79, 'n_batches': 165, 'time': 1.806, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -18.601}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 98, 'batch': 159, 'n_batches': 165, 'time': 1.805, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -18.732}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 99, 'loss': -2.31069, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 99, 'loss': 0.0, 'test_loss': 0.401, 'time': 3.8}\n",
            "epoch 99\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 99, 'batch': 79, 'n_batches': 165, 'time': 1.78, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -19.307}\n",
            "INFO:Trainer:{'type': 'train', 'epoch': 99, 'batch': 159, 'n_batches': 165, 'time': 1.696, 'data_time': 0.001, 'lr': 1.0000000000000006e-12, 'loss': -21.711}\n",
            "INFO:Trainer:{'type': 'train-epoch', 'epoch': 100, 'loss': -2.32674, 'time': 37.5}\n",
            "INFO:Trainer:{'type': 'val-epoch', 'epoch': 100, 'loss': 0.0, 'test_loss': 0.174, 'time': 3.7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-rXm38pvtC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
%%% ====================================================================
%%%  BibTeX-file{
%%%     author          = "Gerry Murray",
%%%     version         = "1.2",
%%%     date            = "2 April 2012",
%%%     filename        = "acmsmall-sample-bibfile.bib",
%%%     address         = "ACM, NY",
%%%     email           = "murray at hq.acm.org",
%%%     codetable       = "ISO/ASCII",
%%%     keywords        = "ACM Reference Format, bibliography, citation, references",
%%%     supported       = "yes",
%%%     docstring       = "This BibTeX database file contains 'bibdata' entries
%%%                        that 'match' the examples provided in the Specifications Document
%%%                        AND, also, 'legacy'-type bibs. It should assist authors in
%%%                        choosing the 'correct' at-bibtype and necessary bib-fields
%%%                        so as to obtain the appropriate ACM Reference Format output.
%%%                        It also contains many 'Standard Abbreviations'. "
%%%  }
%%% ====================================================================


%Entries
@article{Helbing95,
  author  = {D. Helbing and P. Molnar},
  title   = {Social force model for pedestrian dynamics},
  journal = {Physical review E},
  volume  = {},
  number  = {},
  month   = {},
  year    = {1995},
  pages   = {4282-4286},
  doi     = {10.1103/PhysRevE.51.4282},
  url     = {},
  note    = {}
}

@inproceedings{Yi15,
  author    = {Yi, Shuai and Li, Hongsheng and Wang, Xiaogang},
  booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Understanding pedestrian behaviors from stationary crowd groups},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {3488-3496},
  doi       = {10.1109/CVPR.2015.7298971}
}


@article{Alahi16,
  author    = { Alexandre and Goel, Kratarth and Ramanathan, Vignesh and Robicquet, Alexandre and Fei-Fei, Li and Savarese, Silvio},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Social LSTM: Human Trajectory Prediction in Crowded Spaces},
  year      = {2016},
  volume    = {},
  number    = {},
  pages     = {961-971},
  doi       = {10.1109/CVPR.2016.110}
}

@article{Altche17,
  author    = {Altché, Florent and de La Fortelle, Arnaud},
  booktitle = {2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)},
  title     = {An LSTM network for highway trajectory prediction},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {353-359},
  doi       = {10.1109/ITSC.2017.8317913}
}

@inproceedings{Gupta_2018_CVPR,
  author    = {Gupta, Agrim and Johnson, Justin and Fei-Fei, Li and Savarese, Silvio and Alahi, Alexandre},
  title     = {Social GAN: Socially Acceptable Trajectories With Generative Adversarial Networks},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2018}
}

@article{Zhou,
  author     = {Zhou, Bolei and Tang, Xiaoou and Wang, Xiaogang},
  title      = {Learning Collective Crowd Behaviors with Dynamic Pedestrian-Agents},
  year       = {2015},
  issue_date = {January 2015},
  publisher  = {Kluwer Academic Publishers},
  address    = {USA},
  volume     = {111},
  number     = {1},
  issn       = {0920-5691},
  url        = {https://doi.org/10.1007/s11263-014-0735-3},
  doi        = {10.1007/s11263-014-0735-3},
  abstract   = {Collective behaviors characterize the intrinsic dynamics of the crowds. Automatically understanding collective crowd behaviors has important applications to video surveillance, traffic management and crowd control, while it is closely related to scientific fields such as statistical physics and biology. In this paper, a new mixture model of dynamic pedestrian-Agents (MDA) is proposed to learn the collective behavior patterns of pedestrians in crowded scenes from video sequences. From agent-based modeling, each pedestrian in the crowd is driven by a dynamic pedestrian-agent, which is a linear dynamic system with initial and termination states reflecting the pedestrian's belief of the starting point and the destination. The whole crowd is then modeled as a mixture of dynamic pedestrian-agents. Once the model parameters are learned from the trajectories extracted from videos, MDA can simulate the crowd behaviors. It can also infer the past behaviors and predict the future behaviors of pedestrians given their partially observed trajectories, and classify them different pedestrian behaviors. The effectiveness of MDA and its applications are demonstrated by qualitative and quantitative experiments on various video surveillance sequences.
                }
}

@article{humanmotionsurvey,
  title     = {Human motion trajectory prediction: A survey},
  author    = {Rudenko, Andrey and Palmieri, Luigi and Herman, Michael and Kitani, Kris M and Gavrila, Dariu M and Arras, Kai O},
  journal   = {The International Journal of Robotics Research},
  volume    = {39},
  number    = {8},
  pages     = {895--935},
  year      = {2020},
  publisher = {Sage Publications Sage UK: London, England}
}

@inproceedings{infogan,
author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
title = {InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound of the mutual information objective that can be optimized efficiently. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing supervised methods. For an up-to-date version of this paper, please see https://arxiv.org/abs/1606.03657.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {2180–2188},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}

% Zubair Ahmed References

% SocialGAN
@article{DBLP:journals/corr/abs-1803-10892,
  author     = {Agrim Gupta and
                Justin Johnson and
                Li Fei{-}Fei and
                Silvio Savarese and
                Alexandre Alahi},
  title      = {Social {GAN:} Socially Acceptable Trajectories with Generative Adversarial
                Networks},
  journal    = {CoRR},
  volume     = {abs/1803.10892},
  year       = {2018},
  url        = {http://arxiv.org/abs/1803.10892},
  eprinttype = {arXiv},
  eprint     = {1803.10892},
  timestamp  = {Sat, 19 Oct 2019 16:30:04 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1803-10892.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

% SocialWays
@article{DBLP:journals/corr/abs-1904-09507,
  author     = {Javad Amirian and
                Jean{-}Bernard Hayet and
                Julien Pettr{\'{e}}},
  title      = {Social Ways: Learning Multi-Modal Distributions of Pedestrian Trajectories
                with GANs},
  journal    = {CoRR},
  volume     = {abs/1904.09507},
  year       = {2019},
  url        = {http://arxiv.org/abs/1904.09507},
  eprinttype = {arXiv},
  eprint     = {1904.09507},
  timestamp  = {Fri, 26 Apr 2019 13:18:53 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1904-09507.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

% InfoGAN -  do not use this for reference as another infogan reference is already being used in the report
@article{DBLP:journals/corr/ChenDHSSA16,
  author     = {Xi Chen and
                Yan Duan and
                Rein Houthooft and
                John Schulman and
                Ilya Sutskever and
                Pieter Abbeel},
  title      = {InfoGAN: Interpretable Representation Learning by Information Maximizing
                Generative Adversarial Nets},
  journal    = {CoRR},
  volume     = {abs/1606.03657},
  year       = {2016},
  url        = {http://arxiv.org/abs/1606.03657},
  eprinttype = {arXiv},
  eprint     = {1606.03657},
  timestamp  = {Mon, 03 Sep 2018 12:15:29 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/ChenDHSSA16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

% PTP-LSTM
@article{DBLP:journals/corr/abs-2007-00113,
  author     = {Zhe Huang and
                Aamir Hasan and
                Katherine Rose Driggs{-}Campbell},
  title      = {Intention-aware Residual Bidirectional {LSTM} for Long-term Pedestrian
                Trajectory Prediction},
  journal    = {CoRR},
  volume     = {abs/2007.00113},
  year       = {2020},
  url        = {https://arxiv.org/abs/2007.00113},
  eprinttype = {arXiv},
  eprint     = {2007.00113},
  timestamp  = {Tue, 07 Jul 2020 11:09:07 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2007-00113.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

% Human Trajectory Forecasting in Crowds
@article{HTF:DBLP:journals/corr/abs-2007-03639,
  author     = {Parth Kothari and
                Sven Kreiss and
                Alexandre Alahi},
  title      = {Human Trajectory Forecasting in Crowds: {A} Deep Learning Perspective},
  journal    = {CoRR},
  volume     = {abs/2007.03639},
  year       = {2020},
  url        = {https://arxiv.org/abs/2007.03639},
  eprinttype = {arXiv},
  eprint     = {2007.03639},
  timestamp  = {Mon, 20 Jul 2020 14:20:39 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2007-03639.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  pages      = {}
}

@article{diidha,
  author  = {Baldwin, Dare and Baird, Jodie},
  year    = {2001},
  month   = {05},
  pages   = {171-178},
  title   = {Discerning intentions in dynamic human action},
  volume  = {5},
  journal = {Trends in Cognitive Sciences},
  doi     = {10.1016/S1364-6613(00)01615-6}
}

@article{doi:10.1146/annurev.psych.57.102904.190152,
  author   = {Blake, Randolph and Shiffrar, Maggie},
  title    = {Perception of Human Motion},
  journal  = {Annual Review of Psychology},
  volume   = {58},
  number   = {1},
  pages    = {47-73},
  year     = {2007},
  doi      = {10.1146/annurev.psych.57.102904.190152},
  note     = {PMID: 16903802},
  url      = {https://doi.org/10.1146/annurev.psych.57.102904.190152},
  eprint   = {https://doi.org/10.1146/annurev.psych.57.102904.190152},
  abstract = { Abstract Humans, being highly social creatures, rely heavily on the ability to perceive what others are doing and to infer from gestures and expressions what others may be intending to do. These perceptual skills are easily mastered by most, but not all, people, in large part because human action readily communicates intentions and feelings. In recent years, remarkable advances have been made in our understanding of the visual, motoric, and affective influences on perception of human action, as well as in the elucidation of the neural concomitants of perception of human action. This article reviews those advances and, where possible, draws links among those findings. }
}

@article{DBLP:journals/corr/abs-1905-06113,
  author     = {Andrey Rudenko and
                Luigi Palmieri and
                Michael Herman and
                Kris M. Kitani and
                Dariu M. Gavrila and
                Kai Oliver Arras},
  title      = {Human Motion Trajectory Prediction: {A} Survey},
  journal    = {CoRR},
  volume     = {abs/1905.06113},
  year       = {2019},
  url        = {http://arxiv.org/abs/1905.06113},
  eprinttype = {arXiv},
  eprint     = {1905.06113},
  timestamp  = {Sat, 23 Jan 2021 01:17:33 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1905-06113.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{Hanisch2003OnlineSO,
  title   = {Online simulation of pedestrian flow in public buildings},
  author  = {Andr{\'e} Hanisch and Juri Tolujew and Klaus Richter and Thomas Schulze},
  journal = {Proceedings of the 2003 Winter Simulation Conference, 2003.},
  year    = {2003},
  volume  = {2},
  pages   = {1635-1641 vol.2}
}

@article{Lerner2007CrowdsBE,
  title   = {Crowds by Example},
  author  = {Alon Lerner and Yiorgos Chrysanthou and Dani Lischinski},
  journal = {Computer Graphics Forum},
  year    = {2007},
  volume  = {26}
}

@article{Bitgood2006AnAO,
  title   = {An Analysis of Visitor Circulation: Movement Patterns and the General Value Principle},
  author  = {Stephen C. Bitgood},
  journal = {Curator: The Museum Journal},
  year    = {2006},
  volume  = {49},
  pages   = {463-475}
}

@inproceedings{Horni2016TheMT,
  title  = {The Multi-Agent Transport Simulation MATSim},
  author = {Andreas Horni and Kai Nagel and Kay W. Axhausen},
  year   = {2016}
}

@misc{UCY-crowds,
  author  = {Lerner, A. and Chrysanthou, Yiorgos L. and Lischinski, D.},
  doi     = {10.1111/j.1467-8659.2007.01089.x},
  journal = {Computer Graphics Forum},
  issue   = 3,
  pages   = {655--664},
  title   = {{Crowds by example}},
  volume  = 26
}

@inproceedings{ETH-biwi,
  author    = {Pellegrini, S. and Ess, A. and Schindler, K. and van Gool, L.},
  booktitle = {2009 IEEE 12th International Conference on Computer Vision},
  title     = {You'll never walk alone: Modeling social behavior for multi-target tracking},
  year      = {2009},
  volume    = {},
  number    = {},
  pages     = {261-268},
  doi       = {10.1109/ICCV.2009.5459260}
}

@inproceedings{gan,
  author    = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
  pages     = {2672–2680},
  publisher = {Curran Associates, Inc.},
  title     = {Generative Adversarial Nets},
  url       = {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
  volume    = {27},
  year      = {2014}
}

@inproceedings{distant_prediction,
author = {Lee, Namhoon and Choi, Wongun and Vernaza, Paul and Choy, Chris and Torr, Philip and Chandraker, Manmohan},
year = {2017},
month = {07},
pages = {2165-2174},
title = {DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents},
doi = {10.1109/CVPR.2017.233}
}
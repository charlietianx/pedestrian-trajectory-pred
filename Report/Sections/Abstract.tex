Pedestrians trajectory prediction has received significant importance in recent years due to the increase in autonomous systems, specifically in the automotive industry because of the rising number of autonomous vehicles. Different methods can be used to accomplish the trajectory prediction task, but deterministic and non-deterministic methods are commonly used methods. This report follows the non-deterministic method, by using SocialGAN 

Using InfoGAN provides extra controll on the prediction and due to the disentangled model nature 


Many approaches can be used to accomplish the prediction, including deterministic and non-deterministic ways. In this report we conduct research and discuss how to use a non-deterministic method, i.e. deep learning methods to solve the prediction problem. The algorithm we are going to use is a combination of SocialGAN and InfoGAN. Firstly, we train a model by the adopted algorithms. Secondly, we generate trajectory pictures of some samples by the model. Then we observe the trajectories of different latent code values and disentangle one factor from the code, which is the direction of the pedestrian.



Understanding human motion behavior is critical for autonomous moving platforms (like self-driving cars and social robots) if they are to navigate human-centric environments. This is challenging because human motion is inherently multimodal: given a history of human motion paths,
there are many socially plausible ways that people could
move in the future. We tackle this problem by combining
tools from sequence prediction and generative adversarial networks: a recurrent sequence-to-sequence model observes motion histories and predicts future behavior, using
a novel pooling mechanism to aggregate information across
people. We predict socially plausible futures by training adversarially against a recurrent discriminator, and encourage diverse predictions with a novel variety loss. Through
experiments on several datasets we demonstrate that our
approach outperforms prior work in terms of accuracy, variety, collision avoidance, and computational complexity.

This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.